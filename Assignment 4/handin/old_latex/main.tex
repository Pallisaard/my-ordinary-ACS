\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}

\title{ACS-A3}
\author{Rikke Tophøj Heinemann (DTZ190) \\ Marie Elkjær Rødsgaard (DCK495) \\ Rasmus Pallisgaard (DWP992)}
\date{\today}

\begin{document}
\maketitle

\section{Question 1: Concurrency Control Concepts}
%For each of the following items, you are asked to exhibit a schedule fulfilling the requirements stated, as well as to justify why the schedule fulfills the requirements:
\subsection{Show a schedule that is conflict-serializable, but could not have been generated by a S2PL scheduler}
% Show a schedule that is conflict-serializable, but could not have been generated by a strict two-phase locking (S2PL) scheduler. Explain. (1-2 sentences)
%--- 
% Den skal over lappe for at være conflicting og den skal gøre noget det ene sted før den anden er færdig for ikke at være S2PL
% Two actions of the same object conflict if at least one of them is a write
\begin{verbatim}
    T1:         R(X) R(Y) W(X) C
    T2: R(X)                      W(Y) C
\end{verbatim}
This schedule is conflict-serializable and could not be generated by S2PL. it is conflict-serializable because its precedence graph is acyclic (only edge from T2 to T1). At the start T1 and T2 both acquire a shared lock for X, But when T1 want to get and exclusive lock it cant because T2 is not ready to release its lock yet, which breaks the rules for strict 2PL. 


\subsection{Show a schedule that could be generated by a S2PL scheduler, but not by a C2PL scheduler}
%2. Show a schedule that could be generated by a S2PL scheduler, but not by a conservative two-phase locking (C2PL) scheduler. Explain. (1-2 sentences)

\begin{verbatim}
    T1:         R(X) R(Y) W(Y) C
    T2: R(X)                      W(X) C
\end{verbatim}
This is S2PL but not C2PL. It is S2PL since T1 and T2 shares the lock for the read operations and T1 has released the lock when T2 needs to write. It is not C2PL because C2PL requires all the locks for a transaction at the beginning making X and exclusive lock and making it so T1 cant obtain a shared lock on X.

\subsection{Show a schedule that is serializable, but not conflict-serializable. Is your schedule view-serializable?}
%3. Show a schedule that is serializable, but not conflict-serializable. Is your schedule view-serializable? Explain. (1-2 sentences)
\begin{verbatim}
    T1: R(X)        W(X) C
    T2:      W(X) C
    T3:                    W(X) C
\end{verbatim}
This schedule is serializable because it is equivalent to fully completing first T1, T2, and then T3. It is not conflict serializable because the precedence graph has a cycle - specifically one between T1 and T2, as there is a conflict between R(X) in T1 and W(X) in T2, and one between W(X) in T2 and W(X) in T1. 

The reason it is not conflict-serializable is that if we draw the precedence graph then we see that it contains cycles. It is view-serializable since all three conditions hold: T1 reads initial value of X in both this and the serial case explained before; No values written are read afterwards; T3 writes final value in both the displayed schedule and the serial one presented earlier.

\subsection{Show a schedule of two transactions that is not view-serializable and consists of the minimal possible number of read/write actions to have this property.}
%4. Show a schedule of two transactions that is not view-serializable and consists of the minimal possible number of read/write actions to have this property. Explain, in particular also why any schedule with fewer actions is view-serializable. (1-2 sentences)
\begin{verbatim}
    T1: R(A)[1]         R(A)[3]
    T2:         W(A)[2]
\end{verbatim}
%kke helt sikker på den her

% This is the minimum number of actions a schedule with two transactions can have that is not view-serializable. This is not view-serializable because it goes against the definition that If Ti reads value of A written by Tj in S1, then Ti also reads value of A written by Tj in S2. 

This view is not view-serializable and consists of 2 reads and a write (denoted by numbers for an understandable explanation). If we wish to, in any way move the write from T2 to either the beginning or the end to construct a serial schedule, we break with the rules for view equivalence: If we swap [1] and [2], we break with rule 2, as [1] will read a value written by [2] in the new schedule but not in the old one. If we swap [2] and [3] we again break with rule 2. As soon as we remove one of these, the schedule is trivially view-serializable, and if we swap a read for a write (e.g. [1]), then we can suddenly swap 2 writes (here [1] and [2]) to construct a view-equivalent and serial schedule.

\section{Question 2: More Concurrency Control}
\subsection{Could Schedule 1 have been generated by a S2PL scheduler?}
No, schedule 1 is not a Strict 2PL since transaction C has a shared lock on X as transaction B acquires an exclusive lock on X. In strict 2PL the shared lock that C has is only released upon commit, which happens after B acquires an exclusive lock.

\subsection{Could Schedule 1 have been generated by a 2PL scheduler?}
%%% SKu ikke helt sikker på den her.
%No Schedule 1 is not 2Pl either since the Tc acquires a new lock after releasing a lock. This can be seen when Tc W(x) after having released the lock after the R(X) for Tb to W(X). 

% Yes the schedule is 2PL since no new locks are acquired after the shrinking phase. The transactions wait for the locks to be released after the commits and then the other transaction proceeds.
No, the schedule cannot have been generated by 2PL since the lock issue explained above still will not have been solved - while 2PL releases locks as they become unnecessary, the shared lock on X is still needed as transaction C will still try to write to X later on.

%% Så tror hvis man skal forstå det som om at man releaser når man committer at det er 2pl men er ikke sikker.

\subsection{Could Schedule 2 have been generated by a C2PL scheduler?}
Schedule 2 could not have been generated by a C2PL. C2PL requires all the locks necessary for the transaction at the beginning. We see in schedule 2 that both transaction A and C require exclusive locks on X, and C2PL acquires locks at the beginning of schedule execution.

\subsection{Could Schedule 2 have been generated by a 2PL scheduler?}
%% igen ikke helt sikker på den her 
% This is 2pl since again no new locks are acquired after the shirking phase.

No, this is not 2PL. As we begin, both transaction A and C acquire shared locks on X at some point. Later on transaction C acquires an exclusive lock, while transaction A still has a shared lock, which is incompatible with 2PL.


\section{Question 3: Recovery Concepts}
\subsection{In a system implementing force and steal, is it necessary to implement a scheme for undo? What about a scheme for redo?}

If a system implements force it is not necessary to implement a REDO scheme since all update actions will be written to stable storage immediately after being made, making the REDO in case of a crash redundant as data is already in stable storage. If the system implements steal we need to implement an UNDO scheme, as actions that have not yet committed will be able to overwrite data of transactions that have already committed. In cases of abort or crash we need an UNDO to undo the uncommitted changes.

\subsection{What is the difference between volatile and stable storage? What types of failures are survived by each type of storage?}

The difference between volatile storage and stable storage is that volatile storage is lost in the event of a system crash, usually due to it needing constant power and attendance in order to be active. Stable storage is an almost theoretical level storage type that by definition can survive all types of failures. Volatile storage can survive failures in transactions but fail at both system crashes and media failure (e.g. a stick of ram dies). Stable storage can, as mentioned previously, survive any crash.

\subsection{In a system that implements Write-Ahead Logging, which are the two situations in which the log tail must be forced to stable storage? Explain why log forces are necessary in these situations and argue why they are sufficient for durability.}

In WAL, just before we write a page to disk we force all logs from this page in the log tail to stable storage. Furthermore if a transaction is committed, then all logs from this transaction that are in the log tail are forced to disk before this commit is concluded.

In the first case this is necessary as we need to force logs to stable storage to have account of what changes are made to the pages on the same storage media. In the second case, given we use non-force we are allowed to data from committed data not be reflected on stable storage, and thus we force the logs to stable storage to be able to reconstruct the given commit in the event of a crash.

Together these ensure that all successful commits can be reconstructed from a crash while ongoing commits can be reconstructed and afterwards rolled back, ensuring durability.

\section{Question 4}

We are given the following log before a crash
\begin{table}[h]
    \centering
    \begin{tabular}{lllll}
        \verb|LSN| & \verb|PREV_LSN| & \verb|XACT_ID| & \verb|TYPE| & \verb|PAGE_ID| \\
        \verb|---| & \verb|--------| & \verb|-------| & \verb|----| & \verb|-------| \\
        \verb|1| & \verb|-| & \verb|-| & \verb|begin CKPT| & \verb|-| \\
        \verb|2| & \verb|-| & \verb|-| & \verb|end CKPT| & \verb|-| \\
        \verb|3| & \verb|NULL| & \verb|T1| & \verb|update| & \verb|P2| \\
        \verb|4| & \verb|3| & \verb|T1| & \verb|update| & \verb|P1| \\
        \verb|5| & \verb|NULL| & \verb|T2| & \verb|update| & \verb|P1| \\
        \verb|6| & \verb|NULL| & \verb|T3| & \verb|update| & \verb|P2| \\
        \verb|7| & \verb|6| & \verb|T3| & \verb|commit| & \verb|-| \\
        \verb|8| & \verb|5| & \verb|T2| & \verb|commit| & \verb|-| \\
        \verb|9| & \verb|4| & \verb|T1| & \verb|update| & \verb|P2| \\
        \verb|10| & \verb|8| & \verb|T2| & \verb|end| & \verb|-| \\
        \verb|----| & \verb|XXXXXX | & \verb|CRASH!| & \verb|XXXXXX| & \verb|----| 
    \end{tabular}
\end{table}

\subsection{Show the state of the transaction table and the dirty page table after the recovery phase}

We have three transactions: T1, T2, and T3. Transactions have definitively been removed from the transaction table once and \verb|end| record has been logged, which has only happened for T2. Every transaction in the transaction table has the status \verb|Undo| except if a \verb|commit| record has been logged, in which case the status is set to \verb|commit|. \verb|lastLSN| is set to the LSN of the last non-\verb|end| record found through the analysis phase. This gives the following transaction table:

\begin{table}[h]
    \centering
    \begin{tabular}{lll}
        \verb|XACT_ID| & \verb|LAST_LSN| & \verb|STATUS| \\
        \verb|-------| & \verb|--------| & \verb|------| \\
        \verb|T1| & \verb|9| & \verb|UNDO| \\
        \verb|T3| & \verb|8| & \verb|COMMIT| \\
    \end{tabular}
\end{table}

The only page chnges in the log are those for pages P1 and P2. T2 has an end record logged, so its changes are reflected on disk, but this isn't necessarily the case for T1 and T3, both of which has made changes to pages P1 and P2, meaning that both are dirty. This gives the following dirty page table:

\begin{table}[h]
    \centering
    \begin{tabular}{ll}
        \verb|PAGE_ID| & \verb|REC_LSN| \\
        \verb|-------| & \verb|-------| \\
        \verb|P1| & \verb|4| \\
        \verb|P2| & \verb|3| \\
    \end{tabular}
\end{table}

\subsection{Show the sets of winner and loser transactions}

We use the books definition of loser transactions: any transaction that is neither committed nor ended. Let the set $T$ be transactions, $T_L$ be loser transactions and $T_W$ be winner transactions. By the transaction table:
$$
T_L=\{T1\},\;\;T_W=T\setminus T_L=\{T2,T3\}
$$

\subsection{Show the values for the LSNs where the redo phase starts and where the undo phase ends}

The redo phase starts at the smallest (earliest) recLSN in the dirty table, i.e. the oldest update that may or may not have been written to disk. Per the dirty table, the redo phase starts at \verb|REC_LSN|=3.

The undo phase ends at \verb|LSN|=3, since we start the undo phase at the only active transaction T1 and add \verb|prev_LSN|s to \verb|ToUndo| until we reach \verb|LSN|=3 where \verb|prev_LSN| is NULL.

\subsection{Show the set of log records that may cause pages to be rewritten during the redo phase}

In this subsection we assume that for each page, their \verb|pageLSN| initially starts with a value such that \verb|pageLSN|<\verb|LSN| for the first \verb|LSN| encountered per page. The redo phase starts at \verb|LSN|=3 and continues through the log until we reach the final log at \verb|LSN|=10. Between these we see 4 logs that are either updates or CLRs: \verb|LSNs|=3, 4, 5, 6, 9. Thus the set of records that can incur potential rewrites to pages are those with LSNs $\{3, 4, 5, 6, 9\}$.

\subsection{Show the set of log records undone during the undo phase}

As mentioned previously only T1 is active and scheduled for undoing, the undo phase thus begins at \verb|LSN|=9 and moves through records 9 to 4 to 3. This is because all are updates, so we add their \verb|prev_LSN| records to \verb|ToUndo| until we at \verb|LSN|=3 reach \verb|prev_LSN|=NULL. Thus the set of \verb|LSN|s corresponding to logs that are undone is: $\{3, 4, 9\}$

Thus the logs that are undone are those with \verb|LSN|s 3, 4, and 9.

\subsection{Show the contents of the log after the recovery procedure completes}

The analysis and redo phases do not add more records to the log. For each update record undone in the undo phase we add a CLR record to signal this, and for each CLR encountered we check if \verb|undoNextLSN|$\neg$NULL: If it is then \verb|undoNetLSN| is added to \verb|ToUndo|, and if not, an end record is written for the transaction. Since we only encounter updates for the three records encountered in the undo phase, we add three CLRs to the log to signify undoing of these. Thus the log will have the following contents:

\begin{table}[h]
    \centering
    \begin{tabular}{lllll}
        \verb|LSN| & \verb|PREV_LSN| & \verb|XACT_ID| & \verb|TYPE| & \verb|PAGE_ID| \\
        \verb|---| & \verb|--------| & \verb|-------| & \verb|----| & \verb|-------| \\
        \verb|1| & \verb|-| & \verb|-| & \verb|begin CKPT| & \verb|-| \\
        \verb|2| & \verb|-| & \verb|-| & \verb|end CKPT| & \verb|-| \\
        \verb|3| & \verb|NULL| & \verb|T1| & \verb|update| & \verb|P2| \\
        \verb|4| & \verb|3| & \verb|T1| & \verb|update| & \verb|P1| \\
        \verb|5| & \verb|NULL| & \verb|T2| & \verb|update| & \verb|P1| \\
        \verb|6| & \verb|NULL| & \verb|T3| & \verb|update| & \verb|P2| \\
        \verb|7| & \verb|6| & \verb|T3| & \verb|commit| & \verb|-| \\
        \verb|8| & \verb|5| & \verb|T2| & \verb|commit| & \verb|-| \\
        \verb|9| & \verb|4| & \verb|T1| & \verb|update| & \verb|P2| \\
        \verb|10| & \verb|8| & \verb|T2| & \verb|end| & \verb|-| \\
        \verb|11| & \verb|9| & \verb|T1| & \verb|CLR| & \verb|P1| \\
        \verb|12| & \verb|11| & \verb|T1| & \verb|CLR| & \verb|P1| \\
        \verb|13| & \verb|12| & \verb|T1| & \verb|CLR| & \verb|P1| \\
    \end{tabular}
\end{table}


\section{Question 5}

\begin{table}[h]
    \centering
    \begin{tabular}{llllll}
        \verb|LSN| & \verb|PREV_LSN| & \verb|XACT_ID| & \verb|TYPE| & \verb|PAGE_ID| & \verb|UNDONEXTLSN| \\
        \verb|---| & \verb|--------| & \verb|-------| & \verb|----| & \verb|-------| & \verb|-----------| \\
        \verb|1| & \verb|-| & \verb|-| & \verb|begin CKPT| & \verb|-| & \verb|-| \\
        \verb|2| & \verb|-| & \verb|-| & \verb|end CKPT| & \verb|-| & \verb|-| \\
        \verb|3| & \verb|NULL| & \verb|T1| & \verb|update| & \verb|P3| & \verb|-| \\
        \verb|4| & \verb|3| & \verb|T1| & \verb|update| & \verb|P1| & \verb|-| \\
        \verb|5| & \verb|NULL| & \verb|T2| & \verb|update| & \verb|P3| & \verb|-| \\
        \verb|6| & \verb|NULL| & \verb|T3| & \verb|update| & \verb|P2| & \verb|-| \\
        \verb|7| & \verb|5| & \verb|T2| & \verb|update| & \verb|P2| & \verb|-| \\
        \verb|8| & \verb|4| & \verb|T1| & \verb|update| & \verb|P4| & \verb|-| \\
        \verb|9| & \verb|6| & \verb|T3| & \verb|commit| & \verb|-| & \verb|-| \\
        \verb|10| & \verb|8| & \verb|T1| & \verb|abort| & \verb|-| & \verb|-| \\
        \verb|11| & \verb|7| & \verb|T2| & \verb|abort| & \verb|-| & \verb|-| \\
        \verb|12| & \verb|11| & \verb|T2| & \verb|CLR| & \verb|P2| & \verb|A| \\
        \verb|13| & \verb|9| & \verb|T3| & \verb|end| & \verb|-| & \verb|-| \\
        \verb|14| & \verb|10| & \verb|T1| & \verb|CLR| & \verb|P4| & \verb|B| \\
        \verb|15| & \verb|12| & \verb|T2| & \verb|CLR| & \verb|P3| & \verb|C| \\
        \verb|16| & \verb|14| & \verb|T1| & \verb|CLR| & \verb|P1| & \verb|D| \\
    \end{tabular}
\end{table}

\subsection{What are the values for the placeholders for undonextLSN in the CLRs?}

When a CLR is created, an \verb|undoNextLSN| is created which points to the record that was undone as the CLR was appended to the log. Since a CLR undoes an update step, we can look at each CLR from the top down and for each, set \verb|undoLastLSN| to be the \verb|prevLSN| for the update that it undoes, with each successive CLR undoing a write further back in the log for the given transaction.  Using this we get that
$$
A=5,B=4,C=NULL,D=3
$$

\subsection{What are the states of the transaction table and of the dirty page table after the analysis phase of recovery?}

The analysis starts at the \verb|end_checkpoint| record and looks forward through the log. Through the update steps we add all transaction IDs (T1, T2, T3) to the transaction table. Furthermore, through these all pages (P1, P2, P3, P4) are added to the dirty page table with the \verb|recLSN|s (4, 6, 3, 8) since it is at these LCNs where we first make an update to the pages. T3 is committed and ended, so it is removed from the transaction table. The abort records for T1 and T2 do not change anything. All the CLRs do is change the \verb|LAST_LSN|. Because T1 and T2 haven't seen commits, they both have Undo status. Thus we get the following transaction table and dirty page table.

\begin{table}[h]
    \centering
    \begin{tabular}{lll}
        \verb|XACT_ID| & \verb|LAST_LSN| & \verb|STATUS| \\
        \verb|-------| & \verb|--------| & \verb|------| \\
        \verb|T1| & \verb|16| & \verb|UNDO| \\
        \verb|T2| & \verb|15| & \verb|UNDO| \\
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{ll}
        \verb|PAGE_ID| & \verb|REC_LSN| \\
        \verb|-------| & \verb|-------| \\
        \verb|P1| & \verb|4| \\
        \verb|P2| & \verb|6| \\
        \verb|P3| & \verb|3| \\
        \verb|P4| & \verb|8| \\
    \end{tabular}
\end{table}

\subsection{Show the additional log contents after the recovery procedure completes.}

The additional logs are only produced during the undo phase. We begin with $ToUndo=\{(T1,16),(T2,15)\}$, where the first element of a tuple is the transaction and the second element inst \verb|LAST_LSN| field. Upon visiting the first, it is a CLR with an \verb|UNDOLASTLSN|=3, meaning we add $(T1,3)$ to $ToUndo$. $(T2,15)$ is a CLR with an \verb|UNDOLASTLSN|=NULL, so we append an end record. $(T1,3)$ is an update with \verb|PREV_LSN|=NULL, so we add a CLR and an end record afterwards. Thus the additional log contents become the following:

\begin{table}[h]
    \centering
    \begin{tabular}{llllll}
        \verb|LSN| & \verb|PREV_LSN| & \verb|XACT_ID| & \verb|TYPE| & \verb|PAGE_ID| & \verb|UNDONEXTLSN| \\
        \verb|---| & \verb|--------| & \verb|-------| & \verb|----| & \verb|-------| & \verb|-----------| \\
        \verb|17| & \verb|15| & \verb|T2| & \verb|end| & \verb|-| & \verb|-| \\
        \verb|18| & \verb|14| & \verb|T1| & \verb|CLR| & \verb|P3| & \verb|NULL| \\
        \verb|19| & \verb|18| & \verb|T1| & \verb|end| & \verb|-| & \verb|-| \\
    \end{tabular}
\end{table}

\subsection{}
\subsubsection{Which log records could trigger writes to stable storage during normal operation in the scenario above? Why?}

The update log, abort, end, and CL records do not under normal operation trigger writes to stable storage. A commit record on the other hand does write to stable storage, because once it is recorded, the log tail up until this commit record is written to stable storage.

\subsubsection{Following the ARIES log record structure introduced in the course for update records, is there any information that would not need to be written to stable storage in such a scenario? Why/why not?}

While we load all non-volatile storage into volatile storage on start up, we still need to write logs to stable storage so we can recover in the case of a crash. The common fields (\verb|PREV_LSN|, \verb|XACT_ID|, \verb|TYPE|) need to be present for operation of the recovery process - \verb|PREV_LSN| for use in the undo process, \verb|XACT_ID| and \verb|TYPE| for info related to the transaction and type of record. The page id, the length, and the offset are all needed to know where to write data in the pages, and before/after images are needed so we can undo/redo these records.

\end{document}
